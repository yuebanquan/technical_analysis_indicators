{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "\n",
    "start = datetime.datetime(2000, 1, 1)\n",
    "end = datetime.datetime(2021, 8, 11)\n",
    "df = web.DataReader('GOOGL', 'stooq', start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def Stock_Price_LSTM_Data_Precesing(df, mem_his_days, pre_days):\n",
    "    df.dropna(inplace=True)\n",
    "    df.sort_index(inplace=True)  # 按时间排序\n",
    "\n",
    "    df['label'] = df['Close'].shift(-pre_days)  # 收盘价前移10天作为label\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    sca_X = scaler.fit_transform(df.iloc[:, :-1])  # 标准化(不包括最后一列label)\n",
    "\n",
    "    from collections import deque\n",
    "\n",
    "    deq = deque(maxlen=mem_his_days)  # 设定队列, 最大长度为记忆天数\n",
    "\n",
    "    X = []\n",
    "    for i in sca_X:\n",
    "        deq.append(list(i))\n",
    "        if len(deq) == mem_his_days:\n",
    "            X.append(list(deq))\n",
    "\n",
    "    X_lately = X[-pre_days:]\n",
    "    X = X[:-pre_days]  # 删除最后几行(预测天数), 因为没有label\n",
    "\n",
    "    y = df['label'].values[mem_his_days - 1:-pre_days]\n",
    "\n",
    "    import numpy as np\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y, X_lately"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "mem_his_days = 10  # 记忆天数: 10天\n",
    "pre_days = 10  # 预测10天后"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "X, y, X_lately = Stock_Price_LSTM_Data_Precesing(df, 10, 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4255\n",
      "4255\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(y))\n",
    "print(len(X_lately))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "构建lstm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 20:53:03.122854: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-25 20:53:03.289782: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-25 20:53:03.574007: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-25 20:53:03.619851: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-25 20:53:03.718875: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/120 [..............................] - ETA: 4:59 - loss: 1162.5134 - mape: 100.2654"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 20:53:03.897219: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-25 20:53:03.969810: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 1456.6760 - mape: 85.6720"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 20:53:06.887782: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-25 20:53:06.949818: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-25 20:53:06.986563: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-25 20:53:07.023424: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 6s 27ms/step - loss: 1456.6760 - mape: 85.6720 - val_loss: 1246.0389 - val_mape: 67.6646\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1255.5714 - mape: 64.6082 - val_loss: 1161.1906 - val_mape: 61.4738\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1180.2516 - mape: 58.7051 - val_loss: 1098.0509 - val_mape: 57.8215\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1121.6647 - mape: 55.0075 - val_loss: 1043.6600 - val_mape: 55.5319\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 1066.6799 - mape: 52.7469 - val_loss: 995.7532 - val_mape: 54.6889\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 3s 21ms/step - loss: 1018.7001 - mape: 51.8178 - val_loss: 952.7134 - val_mape: 55.0045\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 978.1583 - mape: 52.9962 - val_loss: 913.9058 - val_mape: 56.4265\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 938.5458 - mape: 53.9376 - val_loss: 879.3266 - val_mape: 58.5963\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 905.0493 - mape: 56.5333 - val_loss: 847.7517 - val_mape: 61.6217\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 873.6927 - mape: 59.2968 - val_loss: 819.5826 - val_mape: 65.2324\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 845.2465 - mape: 61.9394 - val_loss: 794.5250 - val_mape: 68.9538\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 821.8259 - mape: 65.3258 - val_loss: 772.2062 - val_mape: 72.6600\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 801.0350 - mape: 68.2759 - val_loss: 752.6980 - val_mape: 76.2628\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 780.9526 - mape: 71.4385 - val_loss: 735.1203 - val_mape: 79.8585\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 761.4155 - mape: 73.7758 - val_loss: 719.4551 - val_mape: 83.3899\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 746.3730 - mape: 77.0919 - val_loss: 706.0446 - val_mape: 86.7206\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 734.4877 - mape: 79.6188 - val_loss: 694.4346 - val_mape: 89.9517\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 722.0948 - mape: 82.7778 - val_loss: 684.2507 - val_mape: 93.0867\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 714.5109 - mape: 85.2317 - val_loss: 675.6751 - val_mape: 96.0086\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 707.9316 - mape: 88.2883 - val_loss: 668.2784 - val_mape: 98.8067\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 698.2386 - mape: 89.7614 - val_loss: 662.2756 - val_mape: 101.3379\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 691.0118 - mape: 92.3772 - val_loss: 657.0588 - val_mape: 103.8359\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 2s 20ms/step - loss: 686.3105 - mape: 94.4768 - val_loss: 652.8481 - val_mape: 106.1227\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 685.5717 - mape: 96.6435 - val_loss: 649.3802 - val_mape: 108.2810\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 664.6760 - mape: 88.5779 - val_loss: 516.0352 - val_mape: 35.8856\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 537.6121 - mape: 31.0274 - val_loss: 482.2169 - val_mape: 29.0754\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 501.1208 - mape: 27.3268 - val_loss: 453.3039 - val_mape: 25.6953\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 474.8484 - mape: 23.8599 - val_loss: 427.6851 - val_mape: 22.2195\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 446.1823 - mape: 22.1282 - val_loss: 403.6644 - val_mape: 20.2053\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 429.0146 - mape: 20.9479 - val_loss: 381.9716 - val_mape: 19.1476\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 405.7701 - mape: 19.7222 - val_loss: 362.6794 - val_mape: 19.4292\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 382.9734 - mape: 18.7923 - val_loss: 344.5037 - val_mape: 18.6789\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 367.8117 - mape: 18.1976 - val_loss: 327.4403 - val_mape: 18.2385\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 353.4114 - mape: 17.6440 - val_loss: 311.4124 - val_mape: 15.8729\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 339.0372 - mape: 16.7526 - val_loss: 296.4954 - val_mape: 16.5546\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 319.2211 - mape: 16.2953 - val_loss: 282.8840 - val_mape: 15.8610\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 306.3496 - mape: 15.7058 - val_loss: 269.5640 - val_mape: 16.2760\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 292.1024 - mape: 15.3035 - val_loss: 257.6381 - val_mape: 15.0332\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 286.3708 - mape: 15.0725 - val_loss: 245.4655 - val_mape: 15.8106\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 274.5578 - mape: 14.5541 - val_loss: 233.9843 - val_mape: 15.6114\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 261.4781 - mape: 13.9414 - val_loss: 223.1309 - val_mape: 14.3013\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 250.9905 - mape: 13.5718 - val_loss: 213.8147 - val_mape: 13.7757\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 237.4756 - mape: 13.1790 - val_loss: 202.8622 - val_mape: 12.6121\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 228.2626 - mape: 12.7343 - val_loss: 194.2013 - val_mape: 14.6669\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 219.9408 - mape: 12.2660 - val_loss: 186.0140 - val_mape: 12.8240\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 2s 19ms/step - loss: 211.4541 - mape: 12.0259 - val_loss: 178.8745 - val_mape: 14.4932\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 204.2439 - mape: 11.8361 - val_loss: 170.9877 - val_mape: 12.8474\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 194.8094 - mape: 11.4543 - val_loss: 165.2713 - val_mape: 13.0719\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 188.0904 - mape: 11.3484 - val_loss: 155.8620 - val_mape: 11.8077\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 182.6565 - mape: 10.8534 - val_loss: 151.6942 - val_mape: 13.2734\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2a2a9e910>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "# 构建第一层\n",
    "model.add(LSTM(10, input_shape=X.shape[1:], activation='tanh', return_sequences=True))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 构建第二层\n",
    "model.add(LSTM(10, activation='tanh', return_sequences=True))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 构建第三层\n",
    "model.add(LSTM(10, activation='tanh'))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 构建全连接层\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 输出层\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 编译\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mape'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:38:54.942341: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 1156.0809 - mape: 87.4772"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:39:10.090685: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 17s 127ms/step - loss: 1156.0809 - mape: 87.4772 - val_loss: 379.7974 - val_mape: 55.6922\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 14s 117ms/step - loss: 184.1381 - mape: 37.0181 - val_loss: 35.2082 - val_mape: 14.2493\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 91.1165 - mape: 22.7248 - val_loss: 31.7139 - val_mape: 12.7926\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 15s 121ms/step - loss: 71.7090 - mape: 20.9853 - val_loss: 31.9519 - val_mape: 12.0242\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 14s 118ms/step - loss: 53.8750 - mape: 19.1681 - val_loss: 39.0508 - val_mape: 12.9677\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 46.6513 - mape: 18.4253 - val_loss: 50.1344 - val_mape: 12.5182\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 13s 109ms/step - loss: 38.6148 - mape: 17.5123 - val_loss: 52.1435 - val_mape: 13.7638\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 36.0932 - mape: 16.7700 - val_loss: 25.3130 - val_mape: 9.7503\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 32.2609 - mape: 15.8914 - val_loss: 51.1418 - val_mape: 13.7355\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 13s 109ms/step - loss: 28.8195 - mape: 15.2903 - val_loss: 28.1894 - val_mape: 8.8229\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 21.4091 - mape: 14.2710 - val_loss: 52.5308 - val_mape: 11.6757\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 17.2984 - mape: 13.3268 - val_loss: 69.8419 - val_mape: 12.9620\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 15.0532 - mape: 12.7188 - val_loss: 51.0456 - val_mape: 11.6684\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 17.5669 - mape: 12.3634 - val_loss: 50.3057 - val_mape: 10.8864\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 11.5636 - mape: 11.6997 - val_loss: 91.1684 - val_mape: 15.8516\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 10.7789 - mape: 11.3859 - val_loss: 82.0743 - val_mape: 14.8028\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 14s 118ms/step - loss: 9.4308 - mape: 10.7155 - val_loss: 80.2586 - val_mape: 13.9442\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 14s 117ms/step - loss: 8.8590 - mape: 10.3715 - val_loss: 77.1167 - val_mape: 13.5169\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 14s 120ms/step - loss: 8.7018 - mape: 10.1736 - val_loss: 99.4155 - val_mape: 15.1614\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 15s 127ms/step - loss: 8.3568 - mape: 9.7678 - val_loss: 79.3965 - val_mape: 12.8399\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 14s 115ms/step - loss: 8.2752 - mape: 9.7979 - val_loss: 103.5968 - val_mape: 16.5887\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 16s 129ms/step - loss: 10.3740 - mape: 9.6824 - val_loss: 79.9232 - val_mape: 13.7563\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 16s 134ms/step - loss: 8.5247 - mape: 9.3662 - val_loss: 95.1386 - val_mape: 14.8661\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 16s 131ms/step - loss: 7.6184 - mape: 9.0770 - val_loss: 69.3482 - val_mape: 14.2899\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 14s 117ms/step - loss: 7.8409 - mape: 8.7964 - val_loss: 96.9772 - val_mape: 16.2341\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 15s 126ms/step - loss: 7.7787 - mape: 9.0885 - val_loss: 107.9084 - val_mape: 16.6711\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 6.7536 - mape: 8.5264 - val_loss: 98.7665 - val_mape: 17.7267\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 6.9589 - mape: 8.4095 - val_loss: 98.5828 - val_mape: 16.2833\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 7.2413 - mape: 8.1710 - val_loss: 93.9948 - val_mape: 16.4426\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 6.5512 - mape: 7.9763 - val_loss: 126.6045 - val_mape: 18.3484\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 15s 128ms/step - loss: 6.7516 - mape: 8.0894 - val_loss: 83.9944 - val_mape: 15.8490\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 14s 121ms/step - loss: 6.1383 - mape: 7.6811 - val_loss: 89.7258 - val_mape: 15.0787\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 14s 117ms/step - loss: 6.9278 - mape: 7.8075 - val_loss: 104.0056 - val_mape: 18.0071\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 14s 117ms/step - loss: 6.3916 - mape: 7.7215 - val_loss: 106.6769 - val_mape: 17.1181\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 6.2328 - mape: 7.4257 - val_loss: 83.8372 - val_mape: 15.4905\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 6.7807 - mape: 7.5723 - val_loss: 94.8123 - val_mape: 17.0734\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 15s 129ms/step - loss: 6.2643 - mape: 7.2723 - val_loss: 112.9028 - val_mape: 19.3797\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 6.2728 - mape: 7.1531 - val_loss: 106.6210 - val_mape: 18.5011\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 6.1608 - mape: 6.9723 - val_loss: 94.6468 - val_mape: 16.2252\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 17s 142ms/step - loss: 6.3244 - mape: 7.1630 - val_loss: 98.1135 - val_mape: 14.8502\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 18s 151ms/step - loss: 6.0337 - mape: 7.0293 - val_loss: 123.6386 - val_mape: 19.5613\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 18s 153ms/step - loss: 6.0780 - mape: 6.8911 - val_loss: 121.2378 - val_mape: 19.1613\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 16s 131ms/step - loss: 5.9317 - mape: 6.9246 - val_loss: 110.8096 - val_mape: 17.8809\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 5.7398 - mape: 6.7710 - val_loss: 98.1223 - val_mape: 15.6057\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 15s 124ms/step - loss: 5.8259 - mape: 6.6742 - val_loss: 110.7355 - val_mape: 17.6388\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 16s 133ms/step - loss: 5.9123 - mape: 6.5295 - val_loss: 100.1695 - val_mape: 15.8708\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 5.7764 - mape: 6.4387 - val_loss: 101.2256 - val_mape: 16.9208\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 5.7555 - mape: 6.3560 - val_loss: 118.0046 - val_mape: 19.6253\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 5.6885 - mape: 6.3670 - val_loss: 132.1241 - val_mape: 20.7012\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 6.0053 - mape: 6.4443 - val_loss: 108.2079 - val_mape: 19.0502\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x2963aedf0>"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "# 构建第一层\n",
    "model.add(LSTM(10, input_shape=X.shape[1:], activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 构建第二层\n",
    "model.add(LSTM(10, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 构建第三层\n",
    "model.add(LSTM(10, activation='relu'))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 构建全连接层\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 输出层\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 编译\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mape'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
