{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "\n",
    "start = datetime.datetime(2000, 1, 1)\n",
    "end = datetime.datetime(2021, 8, 11)\n",
    "df = web.DataReader('GOOGL', 'stooq', start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open      High        Low      Close       Volume    label\n",
      "Date                                                                       \n",
      "2004-08-19    2.50000    2.6015    2.39900    2.50850  894076000.0  2.53775\n",
      "2004-08-20    2.52525    2.7270    2.51250    2.70775  457144000.0  2.50025\n",
      "2004-08-23    2.76875    2.8370    2.72625    2.73500  365488000.0  2.53950\n",
      "2004-08-24    2.78100    2.7900    2.58925    2.62175  305252000.0  2.55750\n",
      "2004-08-25    2.62400    2.7000    2.59700    2.65000  183956000.0  2.55775\n",
      "...               ...       ...        ...        ...          ...      ...\n",
      "2021-08-05  135.68000  136.3500  134.84600  136.25200   17869000.0      NaN\n",
      "2021-08-06  136.04200  136.4720  135.21000  135.73800   20488120.0      NaN\n",
      "2021-08-09  135.94200  137.1840  135.33900  136.91300   17766000.0      NaN\n",
      "2021-08-10  137.34200  137.7720  136.36400  136.80700   19414080.0      NaN\n",
      "2021-08-11  137.18200  137.6820  136.27200  136.27900   15352000.0      NaN\n",
      "\n",
      "[4274 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.sort_index(inplace=True)  # 按时间排序\n",
    "pre_days = 10  # 预测10天后\n",
    "df['label'] = df['Close'].shift(-pre_days)  # 收盘价前移10天作为label\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.10502268 -1.10212588 -1.10698705 -1.10384759  4.89034655]\n",
      " [-1.10403672 -1.0972712  -1.10251527 -1.09607465  2.08674174]\n",
      " [-1.09452862 -1.0930161  -1.09409374 -1.0950116   1.49862459]\n",
      " ...\n",
      " [ 4.10557699  4.10389003  4.13070928  4.13940934 -0.73255801]\n",
      " [ 4.16024373  4.12663547  4.1710932   4.13527417 -0.72198299]\n",
      " [ 4.1539961   4.12315402  4.1674685   4.11467635 -0.74804761]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "sca_X = scaler.fit_transform(df.iloc[:, :-1])  # 标准化(不包括最后一列label)\n",
    "print(sca_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4255\n",
      "10\n",
      "4255\n"
     ]
    }
   ],
   "source": [
    "mem_his_days = 10  # 记忆天数: 10天\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "deq = deque(maxlen=mem_his_days)  # 设定队列, 最大长度为记忆天数\n",
    "\n",
    "X = []\n",
    "for i in sca_X:\n",
    "    deq.append(list(i))\n",
    "    if len(deq) == mem_his_days:\n",
    "        X.append(list(deq))\n",
    "\n",
    "X_lately = X[-pre_days:]\n",
    "X = X[:-pre_days]  # 删除最后几行(预测天数), 因为没有label\n",
    "print(len(X))\n",
    "print(len(X_lately))\n",
    "\n",
    "y = df['label'].values[mem_his_days - 1:-pre_days]\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[-1.10502268, -1.10212588, -1.10698705, -1.10384759,\n          4.89034655],\n        [-1.10403672, -1.0972712 , -1.10251527, -1.09607465,\n          2.08674174],\n        [-1.09452862, -1.0930161 , -1.09409374, -1.0950116 ,\n          1.49862459],\n        ...,\n        [-1.09986838, -1.10074297, -1.10102796, -1.10221888,\n         -0.17897484],\n        [-1.10277744, -1.10246435, -1.10088021, -1.10186778,\n         -0.21480496],\n        [-1.10238696, -1.10317998, -1.10333279, -1.10393537,\n          0.32734388]],\n\n       [[-1.10403672, -1.0972712 , -1.10251527, -1.09607465,\n          2.08674174],\n        [-1.09452862, -1.0930161 , -1.09409374, -1.0950116 ,\n          1.49862459],\n        [-1.09405028, -1.09483419, -1.0994914 , -1.09942959,\n          1.11211607],\n        ...,\n        [-1.10277744, -1.10246435, -1.10088021, -1.10186778,\n         -0.21480496],\n        [-1.10238696, -1.10317998, -1.10333279, -1.10393537,\n          0.32734388],\n        [-1.10581339, -1.10376022, -1.10405183, -1.10270652,\n          1.09558698]],\n\n       [[-1.09452862, -1.0930161 , -1.09409374, -1.0950116 ,\n          1.49862459],\n        [-1.09405028, -1.09483419, -1.0994914 , -1.09942959,\n          1.11211607],\n        [-1.10018077, -1.09831563, -1.09918606, -1.09832753,\n          0.33381178],\n        ...,\n        [-1.10238696, -1.10317998, -1.10333279, -1.10393537,\n          0.32734388],\n        [-1.10581339, -1.10376022, -1.10405183, -1.10270652,\n          1.09558698],\n        [-1.1040953 , -1.10436948, -1.10367754, -1.10416943,\n         -0.18467275]],\n\n       ...,\n\n       [[ 3.7578965 ,  3.75087161,  3.78931738,  3.76603485,\n         -0.72305545],\n        [ 3.79382036,  3.79992129,  3.83817208,  3.80094971,\n         -0.6941891 ],\n        [ 3.8208023 ,  3.77570591,  3.78364393,  3.75288813,\n         -0.69115316],\n        ...,\n        [ 3.78936892,  3.76731177,  3.82182152,  3.80812774,\n         -0.75478578],\n        [ 3.89034621,  3.95747597,  3.9124785 ,  3.98734438,\n         -0.58022594],\n        [ 4.00350637,  3.98989208,  4.01105467,  4.02713562,\n         -0.65039075]],\n\n       [[ 3.79382036,  3.79992129,  3.83817208,  3.80094971,\n         -0.6941891 ],\n        [ 3.8208023 ,  3.77570591,  3.78364393,  3.75288813,\n         -0.69115316],\n        [ 3.7823013 ,  3.74135567,  3.76882993,  3.75152275,\n         -0.7154993 ],\n        ...,\n        [ 3.89034621,  3.95747597,  3.9124785 ,  3.98734438,\n         -0.58022594],\n        [ 4.00350637,  3.98989208,  4.01105467,  4.02713562,\n         -0.65039075],\n        [ 4.03954737,  3.99615868,  3.92445578,  3.94384709,\n         -0.49550758]],\n\n       [[ 3.8208023 ,  3.77570591,  3.78364393,  3.75288813,\n         -0.69115316],\n        [ 3.7823013 ,  3.74135567,  3.76882993,  3.75152275,\n         -0.7154993 ],\n        [ 3.7208793 ,  3.67919255,  3.66446211,  3.65820838,\n         -0.66709885],\n        ...,\n        [ 4.00350637,  3.98989208,  4.01105467,  4.02713562,\n         -0.65039075],\n        [ 4.03954737,  3.99615868,  3.92445578,  3.94384709,\n         -0.49550758],\n        [ 4.12002462,  4.14694389,  4.12830594,  4.10745931,\n         -0.23614263]]])"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4255, 10, 5)\n",
      "(4255,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "120/120 [==============================] - 8s 28ms/step - loss: 1474.7396 - mape: 86.7516 - val_loss: 1202.1136 - val_mape: 69.2783\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 1279.2328 - mape: 66.0838 - val_loss: 1112.6356 - val_mape: 61.0015\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 1203.3047 - mape: 59.9842 - val_loss: 1049.3676 - val_mape: 55.9873\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 1140.8494 - mape: 55.8322 - val_loss: 995.5975 - val_mape: 52.4298\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 1084.8750 - mape: 53.6966 - val_loss: 948.0233 - val_mape: 50.1096\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 1038.1274 - mape: 52.3854 - val_loss: 904.9401 - val_mape: 49.3963\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 993.1796 - mape: 52.7778 - val_loss: 866.8978 - val_mape: 50.2508\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 955.2927 - mape: 53.9250 - val_loss: 833.0605 - val_mape: 52.0103\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 919.2679 - mape: 56.1251 - val_loss: 801.8749 - val_mape: 54.8181\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 887.6887 - mape: 58.4447 - val_loss: 774.6136 - val_mape: 58.0607\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 844.9750 - mape: 47.4309 - val_loss: 726.7394 - val_mape: 36.8005\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 804.0991 - mape: 36.7874 - val_loss: 691.9076 - val_mape: 30.9765\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 768.5861 - mape: 33.7038 - val_loss: 660.5438 - val_mape: 29.6474\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 733.4370 - mape: 31.9800 - val_loss: 630.1956 - val_mape: 27.5303\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 704.1015 - mape: 30.6939 - val_loss: 601.9991 - val_mape: 26.4383\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 674.5500 - mape: 29.3673 - val_loss: 575.0475 - val_mape: 24.7966\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 647.2797 - mape: 28.2108 - val_loss: 549.5870 - val_mape: 23.6717\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 614.5897 - mape: 26.7272 - val_loss: 525.4749 - val_mape: 22.8156\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 593.2466 - mape: 26.1074 - val_loss: 502.4751 - val_mape: 21.7471\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 569.5598 - mape: 25.0340 - val_loss: 480.7722 - val_mape: 21.1148\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 545.2062 - mape: 24.4043 - val_loss: 460.1902 - val_mape: 19.8599\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 524.3330 - mape: 23.6655 - val_loss: 440.6871 - val_mape: 19.5145\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 502.6078 - mape: 23.0267 - val_loss: 421.7756 - val_mape: 18.7319\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 482.5084 - mape: 22.3774 - val_loss: 403.7817 - val_mape: 18.0948\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 466.2256 - mape: 21.8477 - val_loss: 386.7084 - val_mape: 17.6582\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 445.1048 - mape: 21.3253 - val_loss: 370.0685 - val_mape: 17.4519\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 424.6771 - mape: 20.2680 - val_loss: 353.9970 - val_mape: 16.1066\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 413.7802 - mape: 20.0567 - val_loss: 338.9764 - val_mape: 15.9500\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 397.2593 - mape: 19.7437 - val_loss: 324.7432 - val_mape: 15.4352\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 376.7361 - mape: 18.7075 - val_loss: 310.8762 - val_mape: 14.5900\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 365.2444 - mape: 18.8443 - val_loss: 297.6400 - val_mape: 14.1787\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 349.2534 - mape: 18.4766 - val_loss: 285.1983 - val_mape: 13.7445\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 2s 18ms/step - loss: 338.9776 - mape: 17.8398 - val_loss: 273.5075 - val_mape: 13.7585\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 326.1944 - mape: 17.5368 - val_loss: 261.7700 - val_mape: 13.4384\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 311.2571 - mape: 17.0224 - val_loss: 250.9722 - val_mape: 13.8113\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 301.0916 - mape: 16.9051 - val_loss: 240.4635 - val_mape: 13.0055\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 292.7412 - mape: 16.5358 - val_loss: 230.4973 - val_mape: 12.1453\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 2s 13ms/step - loss: 274.3646 - mape: 16.3896 - val_loss: 220.2955 - val_mape: 11.6402\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 267.5371 - mape: 15.9002 - val_loss: 210.9729 - val_mape: 11.6011\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 2s 14ms/step - loss: 257.3766 - mape: 15.4656 - val_loss: 202.1688 - val_mape: 11.0192\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 2s 15ms/step - loss: 246.1943 - mape: 15.5369 - val_loss: 193.6313 - val_mape: 11.1541\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 239.9063 - mape: 15.0543 - val_loss: 185.5159 - val_mape: 10.4862\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 232.4060 - mape: 14.7462 - val_loss: 177.7449 - val_mape: 10.2383\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 222.5609 - mape: 14.8391 - val_loss: 170.5052 - val_mape: 10.0001\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 215.0051 - mape: 14.2680 - val_loss: 163.4211 - val_mape: 9.9096\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 211.1627 - mape: 14.0686 - val_loss: 157.1972 - val_mape: 9.8862\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 196.9845 - mape: 13.8097 - val_loss: 150.6565 - val_mape: 9.2574\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 2s 17ms/step - loss: 194.5622 - mape: 13.6119 - val_loss: 144.6128 - val_mape: 8.7660\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 185.2415 - mape: 13.5808 - val_loss: 138.9878 - val_mape: 8.4529\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 2s 16ms/step - loss: 182.8698 - mape: 13.5480 - val_loss: 134.0221 - val_mape: 8.6978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e9207b5670>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "# 构建第一层\n",
    "model.add(LSTM(10, input_shape=X.shape[1:], activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 构建第二层\n",
    "model.add(LSTM(10, activation='tanh', recurrent_activation='sigmoid', return_sequences=True))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 构建第三层\n",
    "model.add(LSTM(10, activation='tanh', recurrent_activation='sigmoid'))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 构建全连接层\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 输出层\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 编译\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mape'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:38:54.942341: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - ETA: 0s - loss: 1156.0809 - mape: 87.4772"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 16:39:10.090685: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 17s 127ms/step - loss: 1156.0809 - mape: 87.4772 - val_loss: 379.7974 - val_mape: 55.6922\n",
      "Epoch 2/50\n",
      "120/120 [==============================] - 14s 117ms/step - loss: 184.1381 - mape: 37.0181 - val_loss: 35.2082 - val_mape: 14.2493\n",
      "Epoch 3/50\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 91.1165 - mape: 22.7248 - val_loss: 31.7139 - val_mape: 12.7926\n",
      "Epoch 4/50\n",
      "120/120 [==============================] - 15s 121ms/step - loss: 71.7090 - mape: 20.9853 - val_loss: 31.9519 - val_mape: 12.0242\n",
      "Epoch 5/50\n",
      "120/120 [==============================] - 14s 118ms/step - loss: 53.8750 - mape: 19.1681 - val_loss: 39.0508 - val_mape: 12.9677\n",
      "Epoch 6/50\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 46.6513 - mape: 18.4253 - val_loss: 50.1344 - val_mape: 12.5182\n",
      "Epoch 7/50\n",
      "120/120 [==============================] - 13s 109ms/step - loss: 38.6148 - mape: 17.5123 - val_loss: 52.1435 - val_mape: 13.7638\n",
      "Epoch 8/50\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 36.0932 - mape: 16.7700 - val_loss: 25.3130 - val_mape: 9.7503\n",
      "Epoch 9/50\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 32.2609 - mape: 15.8914 - val_loss: 51.1418 - val_mape: 13.7355\n",
      "Epoch 10/50\n",
      "120/120 [==============================] - 13s 109ms/step - loss: 28.8195 - mape: 15.2903 - val_loss: 28.1894 - val_mape: 8.8229\n",
      "Epoch 11/50\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 21.4091 - mape: 14.2710 - val_loss: 52.5308 - val_mape: 11.6757\n",
      "Epoch 12/50\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 17.2984 - mape: 13.3268 - val_loss: 69.8419 - val_mape: 12.9620\n",
      "Epoch 13/50\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 15.0532 - mape: 12.7188 - val_loss: 51.0456 - val_mape: 11.6684\n",
      "Epoch 14/50\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 17.5669 - mape: 12.3634 - val_loss: 50.3057 - val_mape: 10.8864\n",
      "Epoch 15/50\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 11.5636 - mape: 11.6997 - val_loss: 91.1684 - val_mape: 15.8516\n",
      "Epoch 16/50\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 10.7789 - mape: 11.3859 - val_loss: 82.0743 - val_mape: 14.8028\n",
      "Epoch 17/50\n",
      "120/120 [==============================] - 14s 118ms/step - loss: 9.4308 - mape: 10.7155 - val_loss: 80.2586 - val_mape: 13.9442\n",
      "Epoch 18/50\n",
      "120/120 [==============================] - 14s 117ms/step - loss: 8.8590 - mape: 10.3715 - val_loss: 77.1167 - val_mape: 13.5169\n",
      "Epoch 19/50\n",
      "120/120 [==============================] - 14s 120ms/step - loss: 8.7018 - mape: 10.1736 - val_loss: 99.4155 - val_mape: 15.1614\n",
      "Epoch 20/50\n",
      "120/120 [==============================] - 15s 127ms/step - loss: 8.3568 - mape: 9.7678 - val_loss: 79.3965 - val_mape: 12.8399\n",
      "Epoch 21/50\n",
      "120/120 [==============================] - 14s 115ms/step - loss: 8.2752 - mape: 9.7979 - val_loss: 103.5968 - val_mape: 16.5887\n",
      "Epoch 22/50\n",
      "120/120 [==============================] - 16s 129ms/step - loss: 10.3740 - mape: 9.6824 - val_loss: 79.9232 - val_mape: 13.7563\n",
      "Epoch 23/50\n",
      "120/120 [==============================] - 16s 134ms/step - loss: 8.5247 - mape: 9.3662 - val_loss: 95.1386 - val_mape: 14.8661\n",
      "Epoch 24/50\n",
      "120/120 [==============================] - 16s 131ms/step - loss: 7.6184 - mape: 9.0770 - val_loss: 69.3482 - val_mape: 14.2899\n",
      "Epoch 25/50\n",
      "120/120 [==============================] - 14s 117ms/step - loss: 7.8409 - mape: 8.7964 - val_loss: 96.9772 - val_mape: 16.2341\n",
      "Epoch 26/50\n",
      "120/120 [==============================] - 15s 126ms/step - loss: 7.7787 - mape: 9.0885 - val_loss: 107.9084 - val_mape: 16.6711\n",
      "Epoch 27/50\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 6.7536 - mape: 8.5264 - val_loss: 98.7665 - val_mape: 17.7267\n",
      "Epoch 28/50\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 6.9589 - mape: 8.4095 - val_loss: 98.5828 - val_mape: 16.2833\n",
      "Epoch 29/50\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 7.2413 - mape: 8.1710 - val_loss: 93.9948 - val_mape: 16.4426\n",
      "Epoch 30/50\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 6.5512 - mape: 7.9763 - val_loss: 126.6045 - val_mape: 18.3484\n",
      "Epoch 31/50\n",
      "120/120 [==============================] - 15s 128ms/step - loss: 6.7516 - mape: 8.0894 - val_loss: 83.9944 - val_mape: 15.8490\n",
      "Epoch 32/50\n",
      "120/120 [==============================] - 14s 121ms/step - loss: 6.1383 - mape: 7.6811 - val_loss: 89.7258 - val_mape: 15.0787\n",
      "Epoch 33/50\n",
      "120/120 [==============================] - 14s 117ms/step - loss: 6.9278 - mape: 7.8075 - val_loss: 104.0056 - val_mape: 18.0071\n",
      "Epoch 34/50\n",
      "120/120 [==============================] - 14s 117ms/step - loss: 6.3916 - mape: 7.7215 - val_loss: 106.6769 - val_mape: 17.1181\n",
      "Epoch 35/50\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 6.2328 - mape: 7.4257 - val_loss: 83.8372 - val_mape: 15.4905\n",
      "Epoch 36/50\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 6.7807 - mape: 7.5723 - val_loss: 94.8123 - val_mape: 17.0734\n",
      "Epoch 37/50\n",
      "120/120 [==============================] - 15s 129ms/step - loss: 6.2643 - mape: 7.2723 - val_loss: 112.9028 - val_mape: 19.3797\n",
      "Epoch 38/50\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 6.2728 - mape: 7.1531 - val_loss: 106.6210 - val_mape: 18.5011\n",
      "Epoch 39/50\n",
      "120/120 [==============================] - 17s 139ms/step - loss: 6.1608 - mape: 6.9723 - val_loss: 94.6468 - val_mape: 16.2252\n",
      "Epoch 40/50\n",
      "120/120 [==============================] - 17s 142ms/step - loss: 6.3244 - mape: 7.1630 - val_loss: 98.1135 - val_mape: 14.8502\n",
      "Epoch 41/50\n",
      "120/120 [==============================] - 18s 151ms/step - loss: 6.0337 - mape: 7.0293 - val_loss: 123.6386 - val_mape: 19.5613\n",
      "Epoch 42/50\n",
      "120/120 [==============================] - 18s 153ms/step - loss: 6.0780 - mape: 6.8911 - val_loss: 121.2378 - val_mape: 19.1613\n",
      "Epoch 43/50\n",
      "120/120 [==============================] - 16s 131ms/step - loss: 5.9317 - mape: 6.9246 - val_loss: 110.8096 - val_mape: 17.8809\n",
      "Epoch 44/50\n",
      "120/120 [==============================] - 17s 138ms/step - loss: 5.7398 - mape: 6.7710 - val_loss: 98.1223 - val_mape: 15.6057\n",
      "Epoch 45/50\n",
      "120/120 [==============================] - 15s 124ms/step - loss: 5.8259 - mape: 6.6742 - val_loss: 110.7355 - val_mape: 17.6388\n",
      "Epoch 46/50\n",
      "120/120 [==============================] - 16s 133ms/step - loss: 5.9123 - mape: 6.5295 - val_loss: 100.1695 - val_mape: 15.8708\n",
      "Epoch 47/50\n",
      "120/120 [==============================] - 15s 122ms/step - loss: 5.7764 - mape: 6.4387 - val_loss: 101.2256 - val_mape: 16.9208\n",
      "Epoch 48/50\n",
      "120/120 [==============================] - 16s 137ms/step - loss: 5.7555 - mape: 6.3560 - val_loss: 118.0046 - val_mape: 19.6253\n",
      "Epoch 49/50\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 5.6885 - mape: 6.3670 - val_loss: 132.1241 - val_mape: 20.7012\n",
      "Epoch 50/50\n",
      "120/120 [==============================] - 14s 113ms/step - loss: 6.0053 - mape: 6.4443 - val_loss: 108.2079 - val_mape: 19.0502\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2963aedf0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "# 构建第一层\n",
    "model.add(LSTM(10, input_shape=X.shape[1:], activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 构建第二层\n",
    "model.add(LSTM(10, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 构建第三层\n",
    "model.add(LSTM(10, activation='relu'))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 构建全连接层\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.1))  # 为防止过拟合, 删除0.1%的神经元\n",
    "\n",
    "# 输出层\n",
    "model.add(Dense(1))\n",
    "\n",
    "# 编译\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mape'])\n",
    "\n",
    "# 训练模型\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
